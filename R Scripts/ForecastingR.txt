Forecasting in R

### Exploring and visualizing time series in R ###

# Create "ts" (time series) object
# Read the data from Excel into R
mydata <- read_excel("exercise1.xlsx")
# Look at the first few lines of mydata
head(mydata)
# Create a ts object called myts
myts <- ts(mydata[,2:4], start = c(1981, 1), frequency = 4)

#datasets in forecast package
gold  : containing gold prices in US dollars
woolyrnq : containing information on the production of woollen yarn in Australia
gas : containing Australian gas production

# Plot the data with facetting
autoplot(myts, facets = TRUE)
# Plot the data without facetting
autoplot(myts, facets = FALSE)
# Plot the three series
autoplot(gold)
autoplot(woolyrnq)
autoplot(gas)
# Find the outlier in the gold series
goldoutlier <- which.max(gold)
# Look at the seasonal frequencies of the three series
frequency(gold)
frequency(woolyrnq)
frequency(gas)

# Load the fpp2 package
library("fpp2")
# Create plots of the a10 data
autoplot(a10)
ggseasonplot(a10)
# Produce a polar coordinate season plot for the a10 data
ggseasonplot(a10, polar = TRUE)
# Restrict the ausbeer data to start in 1992
beer <- window(ausbeer, start = 1992)
# Make plots of the beer data
autoplot(beer)
ggsubseriesplot(beer)

# The correlations associated with the lag plots form 
# what is called the autocorrelation function (ACF). 
# The ggAcf() function produces ACF plots.
# Create an autoplot of the oil data
autoplot(oil)
# Create a lag plot of the oil data
gglagplot(oil, 1)
# Create an ACF plot of the oil data
ggAcf(oil)


# Plot the annual sunspot numbers
autoplot(sunspot.year)
ggAcf(sunspot.year)
# Save the lag corresponding to maximum autocorrelation
maxlag_sunspot <- 1
# Plot the traffic on the Hyndsight blog
autoplot(hyndsight)
ggAcf(hyndsight)
# Save the lag corresponding to maximum autocorrelation
maxlag_hyndsight <- 7

# White noise = time series that is purely random
# We can test for white noise by looking at an ACF plot or by doing a Ljung-box test
# A p-value greater than 0.05 suggests the data are not significantly different from white noise
set.seed(3) 		# reproducibility
wn <- ts(rnorm(36)) # white noise
autoplot(wn) 		# plot
ggAcf(wn) + ggtitle("Sample ACF for White Noise") 
# Expectation : each correlation is close to zero
# 95 % of all autocorrelations for white noise should lie within the blue lines
# if not : series is probably not white noise

# Ljung-box test :  considers the first "h" autocorrelation values together
# A significant test (small p-value) indicates the data are probably not white noise
Box.test(pigs, lag = 24, fitdf = 0, type ="Lj")
# Plot the original series
autoplot(goog)
# Plot the differenced series
autoplot(diff(goog))
# ACF of the differenced series
ggAcf(diff(goog))
# Ljung-Box test of the differenced series
Box.test(diff(goog), lag = 10, type = "Ljung")



### Benchmark methods and forecast accuracy ###

# a forecast is the mean or median of simulated futures of a time series

# Naive forecast : use most recent observation - naive() (= useful benchmark)
# Naive (incl season) : snaive()

# Use naive() to forecast the goog series
fcgoog <- naive(goog, 20)
# Plot and summarize the forecasts
autoplot(fcgoog)
summary(fcgoog)

# Use snaive() to forecast the ausbeer series
fcbeer <- snaive(ausbeer, 16)
# Plot and summarize the forecasts
autoplot(fcbeer)
summary(fcbeer)

# residuals = forecast errors

fc <- naive(oil)
autoplot(oil, series = "Data") + xlab("Year") +
 autolayer(fitted(fc), series = "Fitted") + 
 ggtitle("Oil production in Saudi Arabia")

# Residuals should look like white noise
autoplot(residuals(fc))
 
# Assumptions : uncorrelated, mean = zero, constant variance, normally distributed 
checkresiduals()

# Check the residuals from the naive forecasts applied to the goog series
goog %>% naive() %>% checkresiduals()
# Do they look like white noise (TRUE or FALSE)
googwn <- TRUE
# Check the residuals from the seasonal naive forecasts applied to the ausbeer series
ausbeer %>% snaive() %>% checkresiduals()
# Do they look like white noise (TRUE or FALSE)
beerwn <- FALSE

# Test set must not be used for any aspect of calculating forecast
# Build forecasts using training set
# A model which fits the training data well will not necessarily forecast well
training <- window(oil, end = 2003)
test <- window(oil, start = 2004)
fc <- naive(training, h = 10)
autoplot(fc) + autolayer(test, series = "Test data")

# Forecast = mean of all observations
meanf()

# Forecast error = difference between observed value and its forecast in the test set (!= residuals)
# residuals = errors on training set (vs test set) and based on one-step forecasts (vs multi-step)
# Compute accuracy using forecast errors on test data

# Measures of forecast accuracy : the smaller the better
# MAE = Mean Absolute Error
# MSE = Mean Squared Error
# RMSE = Root Mean Squared Error
# MAPE = Mean Absolute Percentage Error
# MASE = Mean Absolute Scaled Error
accuracy(fc, test)

# Create the training data as train
train <- subset(gold, end = 1000)
# Compute naive forecasts and save to naive_fc
naive_fc <- naive(train, h = 108)
# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(train, h = 108)
# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, gold)
accuracy(mean_fc, gold)
# Assign one of the two forecasts as bestforecasts
bestforecasts <- naive_fc

# Create three training series omitting the last 1, 2, and 3 years
train1 <- window(vn[, "Melbourne"], end = c(2014, 4))
train2 <- window(vn[, "Melbourne"], end = c(2013, 4))
train3 <- window(vn[, "Melbourne"], end = c(2012, 4))
# Produce forecasts using snaive()
fc1 <- snaive(train1, h = 4)
fc2 <- snaive(train2, h = 4)
fc3 <- snaive(train3, h = 4)
# Use accuracy() to compare the MAPE of each series
accuracy(fc1, vn[, "Melbourne"])["Test set", "MAPE"]
accuracy(fc2, vn[, "Melbourne"])["Test set", "MAPE"]
accuracy(fc3, vn[, "Melbourne"])["Test set", "MAPE"]

# time series cross validation : tsCV()
# With no parameters to be estimated, tsCV with h=1 will give same values as residuals
e <- tsCV(oil, forecastfunction = naive, h = 1)
mean(e^2, na.rm = TRUE)

# MSE increases with forecast horizon
sq <- function(u){u^2}
for (h in 1:10) { 
 oil %>% tsCV(forecastfunction = naive, h = h) %>%
	sq() %>% mean(na.rm = TRUE) %>% print()
}

# Compute cross-validated errors for up to 8 steps ahead
e <- tsCV(goog, forecastfunction = naive, h = 8)
# Compute the MSE values and remove missing values
mse <- colMeans(e^2, na.rm = TRUE)
# Plot the MSE values against the forecast horizon
data.frame(h = 1:8, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()
 
### Exponential smoothing ###

# Simple Exponential Smoothing (SES) 
# more recent observations get more weight
# forecast is same for all point forecasts = mean of the future possible paths
oildata <- window(oil, start = 1996)
fc <- ses(oildata, h = 5)
summary(fc)
autoplot(fc) + ylab("Oil (millions of tonnes)") + xlab("Year")

# Compare two forecasting methods

# Create a training set using subset()
train <- subset(marathon, end = length(marathon) - 20)
# Compute SES and naive forecasts, save to fcses and fcnaive
fcses <- ses(train, h = 20)
fcnaive <- naive(train, h = 20)
# Calculate forecast accuracy measures
accuracy(fcses, marathon)
accuracy(fcnaive, marathon)
# Save the best forecasts as fcbest
fcbest <- fcnaive

# Holt's method : SES with "local linear" trend
# = Same trend for all forecasts
airpassengers %>% holt(h = 5) %>% autoplot

# SES with "damped linear" trend methods
# trend is "damped" to constant (=levels off)
# = short-term forecasts are trended, long-term forecasts are constant
fc1 <- holt(airpassengers, h = 15, PI = FALSE)
fc2 <- holt(airpassengers, damped = TRUE, h = 15, PI = FALSE)
autoplot(airpassengers) + xlab("Year") + ylab("millions")
+ autolayer(fc1, series="Linear trend")
+ autolayer(fc2, series="Damped trend")

# Produce 10 year forecasts of austa using holt()
fcholt <- holt(austa, h = 10)
# Look at fitted model using summary()
summary(fcholt)
# Plot the forecasts
autoplot(fcholt)
# Check that the residuals look like white noise
checkresiduals(fcholt)


# Holt-Winters : additive & multiplicative version
# included seasonality 
# seasonal component averages zero for additive version and 1 for multiplicative version
# if seasonality increases with the level of the series => multiplicative version
aust <- window(austourists, start = 2005)
fc1 <- hw(aust, seasonal = "additive") # damped = FALSE
fc2 <- hw(aust, seasonal = "multiplicative") # damped = FALSE

# Plot the data
autoplot(a10)
# Produce 3 year forecasts
fc <- hw(a10, seasonal = "multiplicative", h = 36)
# Check if residuals look like white noise
checkresiduals(fc)
whitenoise <- FALSE
# Plot forecasts
autoplot(fc)

# Create training data with subset()
train <- subset(hyndsight, end = length(hyndsight) - 28)
# Holt-Winters additive forecasts as fchw
fchw <- hw(train, seasonal = "additive", h = 28)
# Seasonal naive forecasts as fcsn
fcsn <- snaive(train, h = 28)
# Find better forecasts with accuracy()
accuracy(fchw, hyndsight)
accuracy(fcsn, hyndsight)
# Plot the better forecasts
autoplot(fchw)
autoplot(fcsn)

train <- subset(hyndsight, end = length(hyndsight) - 28)
fc1 <- hw(train, seasonal = "additive", h = 28, PI = FALSE)
fc2 <- snaive(train, h = 28, PI = FALSE)
autoplot(hyndsight) +
  autolayer(fc1, series="Holt-Winters") +
  autolayer(fc2, series="Naive seasonal")
accuracy(fc1, hyndsight)
accuracy(fc2, hyndsight)

# ETS models = Error, Trend, Seasonal
# Each exponential smoothing method can be written as an "innovations state space model"
# Trend = none, additive or damped
# Seasonality = none, additive or multiplicative
# Errors = additive or multiplicative   # multiplicative errors = noise increases with the level of the series
# 3 x 3 x 2 = 18 possible state space models
# parameters estimated using the "likelihood" = probability of data arising from the specified model
# Maximum likelihood estimation to optimize parameters & way of generating prediction intervals for all models
# Choose the best model by minimizing corrected version of Akaike's Information Criterion (AICc)
ets(ausair) # returns best model by minimizing AICc # no forecasts

ausair %>% ets() %>% forecast() %>% autoplot()
h02 %>% ets() %>% forecast() %>% autoplot()

# Fit ETS model to austa in fitaus
fitaus <- ets(austa)
# Check residuals
checkresiduals(fitaus)
# Plot forecasts
autoplot(forecast(fitaus))
# Repeat for hyndsight data in fiths
fiths <- ets(hyndsight)
checkresiduals(fiths)
autoplot(forecast(fiths))
# Which model(s) fails test? (TRUE or FALSE)
fitausfail <- FALSE
fithsfail <- TRUE

# Function to return ETS forecasts
fets <- function(y, h) {
  forecast(ets(y), h = h)
}
# Apply tsCV() for both methods
e1 <- tsCV(cement, forecastfunction = fets, h = 4)
e2 <- tsCV(cement, forecastfunction = snaive, h = 4)
# Compute MSE of resulting errors (watch out for missing values)
mean(e1^2, na.rm = TRUE)
mean(e2^2, na.rm = TRUE)
# Copy the best forecast MSE
bestmse <- mean(e2^2, na.rm = TRUE)


# Plot the lynx series
autoplot(lynx)
# Use ets() to model the lynx series
fit <- ets(lynx)
# Use summary() to look at model and parameters
summary(fit)
# Plot 20-year forecasts of the lynx series
fit %>% forecast(h=20) %>% autoplot()


### Forecasting with ARIMA models ###

# ARIMA models provide another approach to time series forecasting. 
# Exponential smoothing and ARIMA models are the two most widely-used approaches to time series forecasting, 
# and provide complementary approaches to the problem. While exponential smoothing models are based on 
# a description of the trend and seasonality in the data, ARIMA models aim to describe the autocorrelations in the data.

# Transformations for variance stabilization
# If data show increasing variation as the level of the series increases, then a transformation can be useful
# square root (x^0.5), cube root (x^0.3333), logarithm(log(x)), inverse (-1/x)

# close to member of family of Box-plot transformations
# log(x) when lambda = 0 & (x^lambda-1)/lambda when lambda != 0

# lambda = 1 : no substantive transformation
# lambda = 0.5 : square root plus linear transformation
# lambda = 1/3 : cube root plus linear tranformation
# lambda = 0 : natural logarithm transformation
# lambda = -1 : inverse transformation

# Box-Cox transformation to balance variation across the series
BoxCox.lambda(usmelec)  # recommended to use : -1  <= lambda <= 1
# Not common to use BoxCox transformation with ETS model, as ETS can 
# handle increasing variance with multiplicative error & seasonal components directly
usmelec %>% ets(lambda = -0.57) %>% forecast(h = 60) %>% autoplot()

boxcox_lambda <- BoxCox.lambda(train)
fc_ets_lambda <- train %>% ets(lambda=boxcox_lambda) %>% forecast(h=6) # forecast
autoplot(fc_ets_lambda) + autolayer(test, series = "Test") + autolayer(fitted(fc_ets_lambda), series='Fitted') #plot
summary(fc_ets_lambda) #data
checkresiduals(fc_ets_lambda) #residuals = white noise (within blue lines) ?
accuracy(fc_ets_lambda, test) #accuracy - ETS (Error,Trend,Seasonal) (BoxCox transformation)

# Plot the series
autoplot(a10)
# Try four values of lambda in Box-Cox transformations
a10 %>% BoxCox(lambda = 0.0) %>% autoplot()
a10 %>% BoxCox(lambda = 0.1) %>% autoplot()
a10 %>% BoxCox(lambda = 0.2) %>% autoplot()
a10 %>% BoxCox(lambda = 0.3) %>% autoplot()
# Compare with BoxCox.lambda()
BoxCox.lambda(a10)

# Non-seasonal differencing for stationarity
# Differencing is a way of making a time series stationary; 
# this means that you remove any systematic patterns such as trend and seasonality from the data. 
# A white noise series is considered a special case of a stationary time series.
# With non-seasonal data, you use lag-1 differences to model changes between observations 
# rather than the observations directly. You have done this before by using the diff() function.

# Seasonal differencing for stationarity
# Plot the data
autoplot(h02)
# Take logs and seasonal differences of h02
difflogh02 <- diff(log(h02), lag = 12)
# Plot difflogh02
autoplot(difflogh02)
# Take another difference and plot
ddifflogh02 <- diff(difflogh02)
autoplot(ddifflogh02)
# Plot ACF of ddifflogh02
ggAcf(ddifflogh02)

# Autoregressive Integrated Moving Average models = ARIMA #
# Autoregressive (AR) = regression of time series with lagged observations as predictors
# Moving average (MA) = regression with lagged errors as predictors
# ARMA = AR + MA = lagged observations & errors as predictors
# can only work with stationary data, so need to difference data first
# I = Integrated = differenced d times to make series stationary => ARIMA(p,d,q)
# p = number of ordinary AR lags
# d = number of lag-1 differences
# q = number of ordinary MA lags
# drift = coefficient c
fit <- auto.arima(usnetelec)
summary(fit)
# minimized AICc values (just like ETS), but cannot compare AICc between different types of models, only within same type of model

# Hyndman-Khandakar algorithm : auto.arima()
- select number of differences d via unit root tests
- select p and q by minimizing AICc
- estimate parameters using maximum likelihood estimation
- use stepwise search to traverse model space, to save time

# Fit an automatic ARIMA model to the austa series
fit <- auto.arima(austa)
# Check that the residuals look like white noise
checkresiduals(fit)
residualsok <- TRUE
# Summarize the model
summary(fit)
# Find the AICc value and the number of differences used
AICc <- -14.46
d <- 1
# Plot forecasts of fit
fit %>% forecast(h = 10) %>% autoplot()

# The Arima() function can be used to select a specific ARIMA model. 
# Its first argument, order, is set to a vector that specifies the values of p, d and q. 
# The second argument, include.constant, is a booolean that determines if the constant c, or drift, should be included. 
# Below is an example of a pipe function that would plot forecasts of usnetelec from an ARIMA(2,1,2) model with drift:
usnetelec %>%
    Arima(order = c(2,1,2), include.constant = TRUE) %>%
    forecast() %>%
    autoplot()

# Plot forecasts from an ARIMA(0,1,1) model with no drift
austa %>% Arima(order = c(0, 1, 1), include.constant = FALSE) %>% forecast() %>% autoplot()
# Plot forecasts from an ARIMA(2,1,3) model with drift
austa %>% Arima(order = c(2,1,3), include.constant = TRUE) %>% forecast() %>% autoplot()
# Plot forecasts from an ARIMA(0,0,1) model with a constant
austa %>% Arima(order = c(0, 0, 1), include.constant = TRUE) %>% forecast() %>% autoplot()
# Plot forecasts from an ARIMA(0,2,1) model with no constant
austa %>% Arima(order = c(0, 2, 1), include.constant = FALSE) %>% forecast() %>% autoplot()

# Use time series cross-validation to compare ARIMA with ETS model
# Set up forecast functions for ETS and ARIMA models
fets <- function(x, h) {
  forecast(ets(x), h = h)
}
farima <- function(x, h) {
  forecast(auto.arima(x),h = h)
}
# Compute CV errors for ETS on austa as e1
e1 <- tsCV(austa, forecastfunction = fets, h = 1)
# Compute CV errors for ARIMA on austa as e2
e2 <- tsCV(austa, forecastfunction = farima, h = 1)
# Find MSE of each model class
mean(e1^2, na.rm = TRUE)
mean(e2^2, na.rm = TRUE)
# Plot 10-year forecasts using the best model class
austa %>% farima(h=10) %>% autoplot()

# Seasonal ARIMA models
ARIMA(P,D,Q)m # seasonal part of model ARIMA(p,d,q)(P,D,Q)[m]:
# P = number of seasonal AR lags
# D = number of seasonal differences
# Q = number of seasonal MA lags
# m = seasonal period

autoplot(debitcards) + 
	xlab("Year") + ylab("million ISK") +
	ggtitle("Retail debit card usage in Iceland")
	
fit <- auto.arima(debitcards, lambda = 0)  # lambda = 0 equals log transformation 
fit %>% forecast(h = 36) %>% autoplot() + xlab("Year")

# auto.arima() : model will be fitted to the transformed data, and forecasts will be back-transformed onto the original scale

# Check that the logged h02 data have stable variance
h02 %>% log() %>% autoplot()
# Fit a seasonal ARIMA model to h02 with lambda = 0
fit <- auto.arima(h02, lambda = 0)
# Summarize the fitted model
summary(fit)
# Record the amount of lag-1 differencing and seasonal differencing used
d <- 1
D <- 1
# Plot 2-year forecasts
fit %>% forecast(h = 24) %>% autoplot()

# Find an ARIMA model for euretail
fit1 <- auto.arima(euretail)
summary(fit1)
# Don't use a stepwise search
fit2 <- auto.arima(euretail, stepwise = FALSE)
summary(fit2)
# AICc of better model
AICc <- 68.39
# Compute 2-year forecasts from better model
fit2 %>% forecast(h = 8) %>% autoplot()


# Use 20 years of the qcement data beginning in 1988
train <- window(qcement, start = 1988, end = c(2007,4))
test <- window(qcement, start = c(2008,1), end = c(2014,1))
# Fit an ARIMA and an ETS model to the training data
fit1 <- auto.arima(train)
fit2 <- ets(train)
# Check that both models have white noise residuals
checkresiduals(fit1)
checkresiduals(fit2)
# Produce forecasts for each model
fc1 <- forecast(fit1, h = 25)
fc2 <- forecast(fit2, h = 25)
# Use accuracy() to find better model based on RMSE
accuracy(fc1, qcement)
accuracy(fc2, qcement)
bettermodel <- fit2










