-----------------------
-- NETWORK ANALYTICS --
-----------------------

=> Basics of networks & network analysis
=> Find important nodes
=> Identify communities of nodes


CONCEPTS
--------
Nodes (Entity) & Edges (Links) = Graph

Undirected graphs = graphs with no directional relationship (fe FB friendship connection)
Directed graph = graphs with inherent directional relationship (fe Twitter users : followers vs following)

Edges can contain weights

Self-loop = nodes that are connected to themselves

Degree centrality = number of neighbours of node / number of all possible neighbours
Betweenness centrality = number shortest paths through node / all possible shortest paths

Degree centrality = connectivity of a node (amount of neighbors of node)
Betweenness centrality = bottleneck-ness of node (amount of shortest paths running through node)

All shortest paths = set of paths which are the shortest paths between all pairs of nodes

Graph algorithms: pathfinding algo's 
Breadth-first-search (BFS) : neighbors of neighbors

Cliques = completely connected graphs (groups of node that are fully connected to one another)
(social version: tightly-knit groups)
Simplest clique : edge
Simplest complex clique : triangle

Maximal cliques = a clique that, when extended by one node is no longer a clique

Subgraph => visualize portions of a large graph: paths, communities/cliques, degrees of separation from a node

Connected component subgraphs = subgraphs of supergraph forming non-connecting parts (?)


EXERCISES
---------
1. NetworkX API basics

import networkx as nx
G = nx.Graph()
G.add_nodes_from([1,2,3])
G.nodes()
>> [1,2,3]
G.add_edge(1,2)
G.edges()
>> [(1,2)]
G.node[1]['label'] = 'blue'
G.nodes(data=True)
>> [(1, {'label':'blue'}), (2, {}), (3, {})]
nx.draw(G)
import matplotlib.pyplot as plt
plt.show()


2. Undirected vs directed graph
G = nx.Graph()  #undirected graph
type(G)
>> networkx.classes.graph.Graph   
D = nx.DiGraph()   # directed graph
type(D) 
>> networkx.classes.digraph.DiGraph 
M = nx.MultiGraph()    #undirected multi-edge graph
type(M)
>> networkx.classes.multigraph.MultiGraph
MD = nx.MultiDiGraph()     #directed multi-edge graph
type(MD)
>> networkx.classes.multidigraph.MultiDiGraph


3. Setting weights of edges
# Set the weight of the edge
T.edge[1][10]['weight'] = 2

# Iterate over all the edges (with metadata)
for u, v, d in T.edges(data=True):
    # Check if fe node 293 is involved
    if 293 in [u,v]:
        # Set the weight to 1.1
        T.edge[u][v]['weight'] = 1.1


4. Check for Self-loops
T.number_of_edges()
T.number_of_nodes()
T.number_of_selfloops()


5. Network Visualization (Matrix, Arc, Circos)
# nxviz ~ nx.from_numpy_matrix(A) #for undirectional matrix Graph()
# nxviz ~ nx.from_numpy_matrix(A, create_using=nx.DiGraph) #for directional matrix DiGraph()

import nxviz as nv
import matplotlib.pyplot as plt
ap = nv.ArcPlot(G)
ap.draw()
plt.show()

m = nv.MatrixPlot(T)  #MatrixPlot: rows & columns = nodes, cells filled in if edge exists
m.draw()
plt.show()

c = nv.CircosPlot(T)
c.draw()
plt.show()

a.ArcPlot(T, node_order='category', node_color='category')
a.draw()
plt.show()


6. Degree centrality
G.edges()
G.neigbors(n)
nx.degree_centrality(G)
>> {1: 1.0, 2: 0.0215, 3: 0.0851, ...}  #dict of nodes (keys) with degree centrality (values)

# Compute the degree of every node: degrees
degrees = [len(T.neighbors(n)) for n in T.nodes()]

# Visualize degree centrality
import matplotlib.pyplot as plt
deg_cent = nx.degree_centrality(T)
# Plot a histogram of the degree centrality distribution of the graph.
plt.figure()
plt.hist(list(deg_cent.values()))
plt.show()
# Plot a histogram of the degree distribution of the graph
plt.figure()
plt.hist(degrees)
plt.show()
# Plot a scatter plot of the centrality distribution and the degree distribution
plt.figure()
plt.scatter(degrees, list(deg_cent.values()))
plt.show()


7. Betweenness centrality
import networkx as nx
G = nx.barbell_graph(m1=5, m2=1)
nx.betweenness_centrality(G)
>> {1: 0.0, 2: 0.0, 3: 0.53, 4: 0.0, ...}  #dict of nodes (keys) with betweenness centrality (values)

# Scatterplot betweenness (x) vs degree centrality (y)
bet_cen = nx.betweenness_centrality(T)
deg_cen = nx.degree_centrality(T)
plt.scatter(list(bet_cen.values()), list(deg_cen.values()))
plt.show()


8. Find nodes with highest degree/betweenness centrality of network 
### Define find_nodes_with_highest_deg_cent()
def find_nodes_with_highest_deg_cent(G):
    # Compute the degree centrality of G: deg_cent
    deg_cent = nx.degree_centrality(G)
    # Compute the maximum degree centrality: max_dc
    max_dc = max(list(deg_cent.values()))
    
    nodes = set()
    # Iterate over the degree centrality dictionary
    for k, v in deg_cent.items():
        # Check if the current value has the maximum degree centrality
        if v == max_dc:
            # Add the current node to the set of nodes
            nodes.add(k)  
    return nodes
    
# Find the node(s) that has the highest degree centrality in T: top_dc
top_dc = find_nodes_with_highest_deg_cent(T)
print(top_dc)
# Write the assertion statement
for node in top_dc:
    assert nx.degree_centrality(T)[node] == max(nx.degree_centrality(T).values())

### Define find_node_with_highest_bet_cent()
def find_node_with_highest_bet_cent(G):
    # Compute betweenness centrality: bet_cent
    bet_cent = nx.betweenness_centrality(G)
    # Compute maximum betweenness centrality: max_bc
    max_bc = max(list(bet_cent.values()))
    nodes = set()
    # Iterate over the betweenness centrality dictionary
    for k, v in bet_cent.items():
        # Check if the current value has the maximum betweenness centrality
        if v == max_bc:   
            # Add the current node to the set of nodes
            nodes.add(k)
    return nodes

# Use that function to find the node(s) that has the highest betweenness centrality in the network: top_bc
top_bc = find_node_with_highest_bet_cent(T)
print(top_bc)
# Write an assertion statement that checks that the node(s) is/are correctly identified.
for node in top_bc:
    assert nx.betweenness_centrality(T)[node] == max(nx.betweenness_centrality(T).values())


9. Looping over all combinations
from itertools import combinations
for n1, n2 in combinations(G.nodes(), 2):
    print(n1, n2)


10. Finding triangle cliques
from itertools import combinations
def is_in_triangle(G, n):
    """
    Checks whether a node `n` in graph `G` is in a triangle relationship or not. 
    Returns a boolean.
    """
    in_triangle = False
    # Iterate over all possible triangle relationship combinations
    for n1, n2 in combinations(G.neighbors(n), 2):
        # Check if an edge exists between n1 and n2
        if G.has_edge(n1, n2):
            in_triangle = True
            break
    return in_triangle


11. Finding nodes involved in triangles (A knows B, B knows C & C knows A)
from itertools import combinations
# Write a function that identifies all nodes in a triangle relationship with a given node.
def nodes_in_triangle(G, n):
    """
    Returns the nodes in a graph `G` that are involved in a triangle relationship with the node `n`.
    """
    triangle_nodes = set([n])
    # Iterate over all possible triangle relationship combinations
    for n1, n2 in combinations(G.neighbors(n),2):
        # Check if n1 and n2 have an edge between them
        if G.has_edge(n1, n2):
            # Add n1 & n2 to triangle_nodes
            triangle_nodes.add(n1)
            triangle_nodes.add(n2)
    return triangle_nodes
   

12. Find open triangles (A know B & A knows C but B doesn't know C)
from itertools import combinations
# Define node_in_open_triangle()
def node_in_open_triangle(G, n):
    """
    Checks whether pairs of neighbors of node `n` in graph `G` are in an 'open triangle' relationship with node `n`.
    """
    in_open_triangle = False
    # Iterate over all possible triangle relationship combinations
    for n1, n2 in combinations(G.neighbors(n),2):
        # Check if n1 and n2 do NOT have an edge between them
        if not G.has_edge(n1,n2):
            in_open_triangle = True           
            break      
    return in_open_triangle

num_open_triangles = 0
# Iterate over all the nodes in T
for n in T.nodes():
    if node_in_open_triangle(T,n):
        num_open_triangles += 1     
print(num_open_triangles)


13. Maximal cliques
import networkx as nx
G = nx.barbell_graph(m1=5, m2=1)
nx.find_cliques(G) #generator object
list(nx.find_cliques(G))
>> [[4,0,1,2,3],[4,5],[6,8,9,10,7],[6,5]]


14. Find maximal cliques of size n
def maximal_cliques(G, size):
    """
    Finds all maximal cliques in graph `G` that are of size `size`.
    """
    mcs = []
    for clique in list(nx.find_cliques(G)):
        if len(clique) == size:
            mcs.append(clique)
    return mcs
# Check that there are 33 maximal cliques of size 3 in the graph T
assert len(maximal_cliques(T, 3)) == 33


15. Subgraphs
import networkx as nx
G = nx.erdos_renyi_graph(n=20, p=0.2)  #random graph
G.nodes()
>> [0,1,2,3, ... ,18,19]
nodes = G.neighbors(8)
>> [2,3,4,10]
nodes.append(8)
G_eight = G.subgraph(nodes)
G_eight.edges()
>> [(8,2),(8,3),(8,4),(8,10),(2,10)]
nx.draw(G_eight, with_labels=True)


16. Draw neighbors of list of nodes 
nodes_of_interest = [29, 38, 42]
# Define get_nodes_and_nbrs()
def get_nodes_and_nbrs(G, nodes_of_interest):
    """
    Returns a subgraph of the graph `G` with only the `nodes_of_interest` and their neighbors.
    """
    nodes_to_draw = []
    # Iterate over the nodes of interest
    for n in nodes_of_interest:
        # Append the nodes of interest to nodes_to_draw
        nodes_to_draw.append(n)
        # Iterate over all the neighbors of node n
        for nbr in G.neighbors(n):
            # Append the neighbors of n to nodes_to_draw
            nodes_to_draw.append(nbr)  
    return G.subgraph(nodes_to_draw)

T_draw = get_nodes_and_nbrs(T, nodes_of_interest)
nx.draw(T_draw)
plt.show()


17. Extract nodes of interest from graph & visualize as subgraph
# Extract the nodes of interest: nodes
nodes = [n for n, d in T.nodes(data=True) if d['occupation'] == 'celebrity']
nodeset = set(nodes)

# Iterate over nodes
for n in nodeset:
    # Compute the neighbors of n: nbrs
    nbrs = T.neighbors(n)
    # Compute the union of nodeset and nbrs: nodeset
    nodeset = nodeset.union(nbrs)

# Compute the subgraph using nodeset: T_sub
T_sub = T.subgraph(nodeset)
nx.draw(T_sub)
plt.show()


18. CASE STUDY // SUMMARY

import networkx as nx
len(G.edges())
len(G.nodes())
nx.degree_centrality(G)
nx.betweenness_centrality(G)

import nxviz as nv
G = nx.erdos_renyi_graph(n=20, p=0.3)
circ = nv.CircoPlot(G, node_color='key', node_group='key')
circ.draw()
plt.show()

G = nx.erdos_renyi_graph(n=100, p=0.03)
nx.connected_component_subgraphs(G)
>> <generator object connected_component_subgraphs>
list(nx.connected_component_subgraphs(G))
>> [ networkx.classes.graph.Graph at 0x10ca24588,
     networkx.classes.graph.Graph at 0x10ca244e0]
for g in list(nx.connected_component_subgraphs(G)):
	print(len(g.nodes())

from nxviz import MatrixPlot
import matplotlib.pyplot as plt
# Calculate the largest connected component subgraph: largest_ccs
largest_ccs = sorted(nx.connected_component_subgraphs(G), key=lambda x: len(x))[-1]
h = MatrixPlot(largest_ccs, node_grouping = 'grouping')
h.draw()
plt.show()

from nxviz.plots import ArcPlot
import matplotlib.pyplot as plt
# Iterate over all the nodes in G, including the metadata
for n, d in G.nodes(data=True):
    # Calculate the degree of each node: G.node[n]['degree']
    G.node[n]['degree'] =  nx.degree(G, n)
a = ArcPlot(G, node_order='degree')
a.draw()
plt.show()

from nxviz import CircosPlot
import matplotlib.pyplot as plt 
for n, d in G.nodes(data=True):
    # Calculate the degree of each node: G.node[n]['degree']
    G.node[n]['degree'] = nx.degree(G, n)
c = CircosPlot(G, node_order='degree', node_grouping='grouping', node_color='grouping')
c.draw()
plt.show()

# Calculate & count the maximal cliques in G: cliques
cliques = nx.find_cliques(G)
print(len(list(cliques)))

import networkx as nx
from nxviz import CircosPlot
import matplotlib.pyplot as plt

# Find the author(s) that are part of the largest maximal clique: largest_clique
largest_clique = sorted(list(nx.find_cliques(G)), key=lambda x:len(x))[-1]
G_lc = G.subgraph(largest_clique)
c = CircosPlot(G_lc)
c.draw()
plt.show()

# Find important users => Degree centrality
# Find largest communities of collaborators => Find largest cliques
# Build collaboration recommendation system => open triangles

### Find the most important users
deg_cent = nx.degree_centrality(G) #most neighbors
max_dc = max(deg_cent.values())
prolific_collaborators = [n for n, dc in deg_cent.items() if dc == max_dc]
print(prolific_collaborators)

### Find largest communities
from nxviz import ArcPlot
import matplotlib.pyplot as plt
largest_max_clique = set(sorted(nx.find_cliques(G), key=lambda x: len(x))[-1])
G_lmc = G.subgraph(largest_max_clique)
# Go out 1 degree of separation
for node in G_lmc.nodes():
    G_lmc.add_nodes_from(G.neighbors(node))
    G_lmc.add_edges_from(zip([node]*len(G.neighbors(node)), G.neighbors(node)))
# Record each node's degree centrality score
for n in G_lmc.nodes():
    G_lmc.node[n]['degree centrality'] = nx.degree_centrality(G_lmc)[n]
# Draw ArcPlot
a = ArcPlot(G_lmc, node_order='degree centrality')
a.draw()
plt.show()

### Recommend based on open triangles
from itertools import combinations
from collections import defaultdict
# Initialize the defaultdict: recommended
recommended = defaultdict(int)
# Iterate over all the nodes in G
for n, d in G.nodes(data=True):
    # Iterate over all possible triangle relationship combinations
    for n1, n2 in combinations(G.neighbors(n), 2):
        # Check whether n1 and n2 do not have an edge
        if not G.has_edge(n1, n2):
            # Increment recommended
            recommended[(n1, n2)] += 1
# Identify the top 10 pairs of users
all_counts = sorted(recommended.values())
top10_pairs = [pair for pair, count in recommended.items() if count > all_counts[-10]]
print(top10_pairs)



--------------------------------
-- NETWORK ANALYTICS - PART 2 --
--------------------------------

CONCEPTS
--------
Bipartite graph = graph partitioned into two sets, nodes are only connected to nodes of other partition (fe customers & products)

Degree centrality (bipartite graph) = number of neighbours / number of nodes in opposite partition (rather than ALL nodes)
(nx.bipartite.degree_centrality(G, nodes) <> nx.degree_centrality(G))

Projection = unipartite representation of bipartite connectivity (fe customers connected by same products) (connectivity of nodes of one partition conditioned on connections to nodes on the other partition) (fe connectivity of customers based on shared purchases)

Matrix representation of bipartite graph: rows = nodes on one partition vs columns = nodes on other partition vs cells = 1 if edge exists else 0

Matrix projection : computable using matrix multiplication: matrix x transposed matrix = projection
=> python: mat @ mat.T

@ = matrix multiplicator operator

Default dictionaries
from collections import defaultdict
d = defaultdict(list)
d['heathrow'].append(0.31) ## regular dictionary would cause error here
d['heathrow'].append(0.48) ## regular dictionary would cause error here
d 
>> {'heathrow': [0.31,0.48] }



19. Bipartite graphs & degree centrality
import networkx as nx
G = nx.Graph()
numbers = range(3)
G.add_nodes_from(numbers, bipartite='customers')
letters = ['a','b']
G.add_nodes_from(letters, bipartite='products')
G.nodes(data=True)
>> [(0, {'bipartite':'customers'}),
    (1, {'bipartite':'customers'}),(2, {'bipartite':'customers'}),
    ('a', {'bipartite':'products'}),('b', {'bipartite':'products'})]


cust_nodes = [n for n,d in G.nodes(data=True) if d['bipartite'] == 'customers']
nx.bipartite.degree_centrality(G, cust_nodes)
>> {0: 0.5, 1: 0.5, 2: 1.0, 'a': 0.333, 'b':1.0}


20. Get nodes from partition 'keyword'
# Define get_nodes_from_partition()
def get_nodes_from_partition(G, partition):
    nodes = []
    # Iterate over each node in the graph G
    for n in G.nodes():
        # Check that the node belongs to the particular partition
        if G.node[n]['bipartite'] == partition:
            nodes.append(n)
    return nodes

print(len(get_nodes_from_partition(G, 'projects')))
print(len(get_nodes_from_partition(G, 'users')))

user_nodes = get_nodes_from_partition(G, 'users')
dcs = nx.degree_centrality(G)
user_dcs = [dcs[n] for n in user_nodes]
plt.yscale('log')
plt.hist(user_dcs, bins=20)
plt.show()


21. Bipartite graphs & recommendation systems
user1_nbrs = G.neighbors('user1')
user3_nbrs = G.neighbors('user3')
set(user1_nbrs).intersection(user3_nbrs)  # objects in both A & B
>> {'repo2'}
set(user3_nbrs).difference(user1_nbrs) # objects in A but not in B
>> {'repo1'}

# find shared repositories of two nodes 
def shared_partition_nodes(G, node1, node2):
    # Check that the nodes belong to the same partition
    assert G.node[node1]['bipartite'] == G.node[node2]['bipartite']

    nbrs1 = G.neighbors(node1)
    nbrs2 = G.neighbors(node2)

    # Compute the overlap using set intersections
    overlap = set(nbrs1).intersection(nbrs2)
    return overlap

print(len(shared_partition_nodes(G, 'u7909', 'u2148')))


22. Define function for user similarity
def user_similarity(G, user1, user2, proj_nodes):
    # Check that the nodes belong to the 'users' partition
    assert G.node[user1]['bipartite'] == 'users'
    assert G.node[user2]['bipartite'] == 'users'

    # Get the set of nodes shared between the two users
    shared_nodes = shared_partition_nodes(G, user1, user2)

    # Return the fraction of nodes in the projects partition
    return len(shared_nodes) / len(proj_nodes)

# Compute the similarity score between users 'u4560' and 'u1880'
project_nodes = get_nodes_from_partition(G, 'projects')
similarity_score = user_similarity(G, 'u4560', 'u1880', project_nodes)

print(similarity_score)


23. Find most similar users
from collections import defaultdict
def most_similar_users(G, user, user_nodes, proj_nodes):
    # Data checks
    assert G.node[user]['bipartite'] == 'users'

    # Get other nodes from user partition
    user_nodes = set(user_nodes)
    user_nodes.remove(user)

    # Create the dictionary: similarities
    similarities = defaultdict(list)
    for n in user_nodes:
        similarity = user_similarity(G, user, n, proj_nodes)
        similarities[similarity].append(n)

    # Compute maximum similarity score: max_similarity
    max_similarity = max(similarities.keys())

    # Return list of users that share maximal similarity
    return similarities[max_similarity]

user_nodes = get_nodes_from_partition(G, 'users')
project_nodes = get_nodes_from_partition(G, 'projects')

print(most_similar_users(G, 'u4560', user_nodes, project_nodes))


24. Recommend products / repositories
def recommend_repositories(G, from_user, to_user):
    # Get the set of repositories that from_user has contributed to
    from_repos = set(G.neighbors(from_user))
    # Get the set of repositories that to_user has contributed to
    to_repos = set(G.neighbors(to_user))

    # Identify repositories that the from_user is connected to that the to_user is not connected to
    return from_repos.difference(to_repos)

# Print the repositories to be recommended
print(recommend_repositories(G, 'u7909', 'u2148'))


25. Reading network data
import networkx as nx
G = nx.read_egdelist('american-revolution.txt')
##Text file:
Barrett.Samuel LondonEnemies {'weight' : 1}
...

import networkx as nx
G = nx.read_edgelist('american-revolution.edgelist')

# Assign nodes to 'clubs' or 'people' partitions
for n, d in G.nodes(data=True):
    if '.' in n:
        G.node[n]['bipartite'] = 'people'
    else:
        G.node[n]['bipartite'] = 'clubs'
        
print(G.edges())


26. Bipartite projection & degree centrality
# Prepare the nodelists needed for computing projections: people, clubs
people = [n for n in G.nodes() if G.node[n]['bipartite'] == 'people']
clubs = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'clubs']
# Compute the people and clubs projections: peopleG, clubsG
peopleG = nx.bipartite.projected_graph(G, people)
clubsG = nx.bipartite.projected_graph(G, clubs)

import matplotlib.pyplot as plt 
# Plot the degree centrality distribution of both node partitions from the original graph
plt.figure()
original_dc = nx.bipartite.degree_centrality(G , people)
plt.hist(list(original_dc.values()), alpha=0.5)
plt.yscale('log')
plt.title('Bipartite degree centrality')
plt.show()

# Plot the degree centrality distribution of the peopleG graph
plt.figure()  
people_dc = nx.degree_centrality(peopleG)
plt.hist(list(people_dc.values()))
plt.yscale('log')
plt.title('Degree centrality of people partition')
plt.show()

# Plot the degree centrality distribution of the clubsG graph
plt.figure() 
clubs_dc = nx.degree_centrality(clubsG)
plt.hist(list(clubs_dc.values()))
plt.yscale('log')
plt.title('Degree centrality of clubs partition')
plt.show()


27. Bipartite graphs as matrices
cust_nodes = [n for n,d in G.nodes(data=True) if d['bipartite']  ='customers']
prod_nodes = [n for n,d in G.nodes(data=True) if d['bipartite']  = 'products']
nx.bipartite.biadjacency_matrix(G, row_order=cust_nodes, column_order=prod_nodes) #sparse matrix

# Get the list of people and list of clubs from the graph: people_nodes, clubs_nodes
people_nodes = get_nodes_from_partition(G, 'people')
clubs_nodes = get_nodes_from_partition(G, 'clubs')
# Compute the biadjacency matrix: bi_matrix
bi_matrix = nx.bipartite.biadjacency_matrix(G, row_order=people_nodes, column_order=clubs_nodes)
# Compute the user-user projection: user_matrix
user_matrix = bi_matrix @ bi_matrix.T
print(user_matrix)


28. Find people & clubs with most connections
import numpy as np
# Find out the names of people who were members of the most number of clubs
diag = user_matrix.diagonal() 
indices = np.where(diag == diag.max())[0]  
print('Number of clubs: {0}'.format(diag.max()))
print('People with the most number of memberships:')
for i in indices:
    print('- {0}'.format(people_nodes[i]))

# Set the diagonal to zero and convert it to a coordinate matrix format
user_matrix.setdiag(0)
users_coo = user_matrix.tocoo()
# Find pairs of users who shared membership in the most number of clubs
indices = np.where(users_coo.data == users_coo.data.max())[0]
print('People with most number of shared memberships:')
for idx in indices:
    print('- {0}, {1}'.format(people_nodes[users_coo.row[idx]], people_nodes[users_coo.col[idx]]))  


29. Representing network data with pandas: list of nodes & list of edges
csv file: user, product, weight
network data in pandas: (+) human-readable & analysis in pandas (-) repetitive, disk space

# Initialize a list to store each edge as a record: nodelist
nodelist = []
for n, d in G_people.nodes(data=True):
    # nodeinfo stores one "record" of data as a dict
    nodeinfo = {'person': n} 
    # Update the nodeinfo dictionary ## adds dictionary d to dictionary nodeinfo
    nodeinfo.update(d)
    # Append the nodeinfo to the node list
    nodelist.append(nodeinfo)
# Create a pandas DataFrame of the nodelist: node_df
node_df = pd.DataFrame(nodelist)
print(node_df.head())

# Initialize a list to store each edge as a record: edgelist
edgelist = []
for n1, n2, d in G_people.edges(data=True):
    # Initialize a dictionary that shows edge information: edgeinfo
    edgeinfo = {'node1':n1, 'node2':n2}
    # Update the edgeinfo data with the edge metadata
    edgeinfo.update(d)
    # Append the edgeinfo to the edgelist
    edgelist.append(edgeinfo) 
# Create a pandas DataFrame of the edgelist: edge_df
edge_df = pd.DataFrame(edgelist)
print(edge_df.head())
print(edgelist[0])


30. Graph differences
## Create graphs by montly time interval
import networkx as nx 
months = range(4, 11)
# Initialize an empty list: Gs
Gs = [] 
for month in months:
    # Instantiate a new undirected graph: G
    G = nx.Graph()
    # Add in all nodes that have ever shown up to the graph
    G.add_nodes_from(data['sender'])
    G.add_nodes_from(data['recipient'])
    # Filter the DataFrame so that there's only the given month
    df_filtered = data[data['month'] == month]  
    # Add edges from filtered DataFrame
    G.add_edges_from(zip(df_filtered['sender'], df_filtered['recipient']))
    # Append G to the list of graphs
    Gs.append(G)
print(len(Gs))

## Calculate differences in graphs
import networkx as nx  
# Instantiate a list of graphs that show edges added: added
added = []
# Instantiate a list of graphs that show edges removed: removed
removed = []
# Here's the fractional change over time
fractional_changes = []
window = 1  
i = 0      
for i in range(len(Gs) - window):
    g1 = Gs[i]
    g2 = Gs[i + window]
    # Compute graph difference here
    added.append(nx.difference(g2, g1))   
    removed.append(nx.difference(g1, g2))
    # Compute change in graph size over time
    fractional_changes.append((len(g2.edges()) - len(g1.edges())) / len(g1.edges()))
# Print the fractional change
print(fractional_changes)

# Visualize
import matplotlib.pyplot as plt
fig = plt.figure()
ax1 = fig.add_subplot(111)
# Plot the number of edges added over time
edges_added = [len(g.edges()) for g in added]
plot1 = ax1.plot(edges_added, label='added', color='orange')
# Plot the number of edges removed over time
edges_removed = [len(g.edges()) for g in removed]
plot2 = ax1.plot(edges_removed, label='removed', color='purple')
# Set yscale to logarithmic scale
ax1.set_yscale('log')  
ax1.legend()
# 2nd axes shares x-axis with 1st axes object
ax2 = ax1.twinx()
# Plot the fractional changes over time
plot3 = ax2.plot(fractional_changes, label='fractional change', color='green')
# Here, we create a single legend for both plots
lines1, labels1 = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc=0)
plt.axhline(0, color='green', linestyle='--')
plt.show()


31. Evolving graph statistics
## Histogram
import matplotlib.pyplot as plt
fig = plt.figure()
# Create a list of the number of edges per month
edge_sizes = [len(g.edges()) for g in Gs]
# Plot edge sizes over time
plt.plot(edge_sizes)
plt.xlabel('Time elapsed from first month (in months).') 
plt.ylabel('Number of edges')                           
plt.show() 

# Cumulative Distribution
import networkx as nx
import matplotlib.pyplot as plt
# Create a list of degree centrality scores month-by-month
cents = []
for G in Gs:
    cent = nx.degree_centrality(G)
    cents.append(cent)
# Plot ECDFs over time
fig = plt.figure()
for i in range(len(cents)):
    x,y = ECDF(cents[i].values())
    plt.plot(x, y, label='Month {0}'.format(i+1)) 
plt.legend()   
plt.show()


32. Overall graph summary
# Get the top 5 unique degree centrality scores: top_dcs
top_dcs = sorted(set(nx.degree_centrality(G).values()), reverse=True)[0:5]
# Create list of nodes that have the top 5 highest overall degree centralities
top_connected = []
for n, dc in nx.degree_centrality(G).items():
    if dc in top_dcs:
        top_connected.append(n)
# Print the number of nodes that share the top 5 degree centrality scores
print(len(top_connected))

import matplotlib.pyplot as plt
from collections import defaultdict
# Create a defaultdict in which the keys are nodes and the values are a list of connectivity scores over time
connectivity = defaultdict(list)
for n in top_connected:
    for g in Gs:
        connectivity[n].append(len(g.neighbors(n)))
# Plot the connectivity for each node
fig = plt.figure() 
for n, conn in connectivity.items(): 
    plt.plot(conn, label=n) 
plt.legend()  
plt.show()


33. CASE STUDY // SUMMARY

### Create Graph from dataframe
import networkx as nx
# Instantiate a new Graph: G
G = nx.Graph()
# Add nodes from each of the partitions
G.add_nodes_from(data['student'], bipartite='student')
G.add_nodes_from(data['forum'], bipartite='forum')
# Add in each edge along with the date the edge was created
for r, d in data.iterrows():
    G.add_edge(d['student'], d['forum'], date=d['date'])

### Plot degree centrality of projected graph : students
import matplotlib.pyplot as plt
import networkx as nx
# Get the student partition's nodes: student_nodes
student_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'student']
# Create the students nodes projection as a graph: G_students
G_students = nx.bipartite.projected_graph(G, nodes=student_nodes)
# Calculate the degree centrality using nx.degree_centrality: dcs
dcs = nx.degree_centrality(G_students)
# Plot the histogram of degree centrality values
plt.hist(list(dcs.values()))
plt.yscale('log')  
plt.show()

### Plot degree centrality of projected graph : forums
import matplotlib.pyplot as plt 
import networkx as nx
# Get the forums partition's nodes: forum_nodes
forum_nodes = [n for n,d in G.nodes(data=True) if d['bipartite'] == 'forum']
# Create the forum nodes projection as a graph: G_forum
G_forum = nx.bipartite.projected_graph(G, forum_nodes)
# Calculate the degree centrality using nx.degree_centrality: dcs
dcs = nx.degree_centrality(G_forum)
# Plot the histogram of degree centrality values
plt.hist(list(dcs.values()))
plt.yscale('log') 
plt.show()  

### Adding filtered edges to graph
import networkx as nx
from datetime import datetime
# Instantiate a new graph: G_sub
G_sub = nx.Graph()
# Add nodes from the original graph
G_sub.add_nodes_from(G.nodes(data=True))
# Add edges using a list comprehension with one conditional on the edge dates, that the date of the edge is earlier than 2004-05-16.
G_sub.add_edges_from([(u, v,d) for u, v, d in G.edges(data=True) if d['date'] < datetime(2004,5,16)])

### Visualize in CircosPlot
from nxviz import CircosPlot
import networkx as nx
import matplotlib.pyplot as plt
# Compute degree centrality scores of each node
dcs = nx.bipartite.degree_centrality(G, nodes=forum_nodes)
for n, d in G_sub.nodes(data=True):
    G_sub.node[n]['dc'] = dcs[n]
# Create the CircosPlot object: c
c = CircosPlot(G_sub, node_color='bipartite', node_grouping='bipartite', node_order='dc')
c.draw()
plt.show() 

### Visualize network data in time
from datetime import timedelta  
import matplotlib.pyplot as plt
# Define current day and timedelta of 2 days
curr_day = dayone
td = timedelta(days=2)
# Initialize an empty list of posts by day
n_posts = []
while curr_day < lastday:
    if curr_day.day == 1:
        print(curr_day) 
    # Filter edges such that they are within the sliding time window: edges
    edges = [(u,v,d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td]
    # Append number of edges to the n_posts list
    n_posts.append(len(edges))
    # Increment the curr_day by the time delta
    curr_day += td
# Create the plot
plt.plot(n_posts)
plt.xlabel('Days elapsed')
plt.ylabel('Number of posts')
plt.show()  

### Visualize degree centrality over time
from datetime import datetime, timedelta
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
# Initialize a new list: mean_dcs
mean_dcs = []
curr_day = dayone
td = timedelta(days=2)
while curr_day < lastday:
    if curr_day.day == 1:
        print(curr_day)  
    # Instantiate a new graph containing a subset of edges: G_sub
    G_sub = nx.Graph()
    # Add nodes from G
    G_sub.add_nodes_from(G.nodes(data=True))
    # Add in edges that fulfill the criteria
    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])
    # Get the students projection
    G_student_sub = nx.bipartite.projected_graph(G_sub, nodes=student_nodes)
    # Compute the degree centrality of the students projection
    dc = nx.degree_centrality(G_student_sub)
    # Append mean degree centrality to the list mean_dcs
    mean_dcs.append(np.mean(list(dc.values())))
    # Increment the time
    curr_day += td
plt.plot(mean_dcs)
plt.xlabel('Time elapsed')
plt.ylabel('Degree centrality.')
plt.show()

### Find most popular forum by day
from datetime import timedelta
import networkx as nx
import matplotlib.pyplot as plt

most_popular_forums = []
highest_dcs = []
curr_day = dayone 
td = timedelta(days=1)  

while curr_day < lastday:  
    if curr_day.day == 1:  
        print(curr_day)  
    G_sub = nx.Graph()
    G_sub.add_nodes_from(G.nodes(data=True))   
    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])
    
    # Get the degree centrality 
    dc = nx.bipartite.degree_centrality(G_sub, forum_nodes)
    # Filter the dictionary such that there's only forum degree centralities
    forum_dcs = {k:v for k,v in dc.items() if k in forum_nodes}
    # Identify the most popular forum(s) 
    most_popular_forum = [n for n, dc in forum_dcs.items() if dc == max(forum_dcs.values()) and dc != 0] 
    most_popular_forums.append(most_popular_forum) 
    # Store the highest dc values in highest_dcs
    highest_dcs.append(max(forum_dcs.values()))
    
    curr_day += td  
    
plt.figure(1) 
plt.plot([len(forums) for forums in most_popular_forums], color='blue', label='Forums')
plt.ylabel('Number of Most Popular Forums')
plt.show()

plt.figure(2)
plt.plot(highest_dcs, color='orange', label='DC Score')
plt.ylabel('Top Degree Centrality Score')
plt.show()










































