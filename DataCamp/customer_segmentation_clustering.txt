CUSTOMER SEGMENTATION IN PYTHON

### K-MEANS CLUSTERING ###

Key steps:
- data preprocessing
- choosing number of clusters
- running k-means clustering on pre-processed data
- analyzing average RFM values of each cluster

Methods to define the number of clusters:
- visual method - elbow criterion
- mathematical method - silhouette coefficient
- experimentation & interpretation


## Running K-Means:

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2, random_state=1)
kmeans.fit(datamart_normalized)
cluster_labels = kmeans.labels_


Analyze RFM values per cluster:

# Create a cluster label column in the original DataFrame:
datamart_rfm_k2 = datamart_rfm.assign(Cluster = cluster_labels)
# Calculate average RFM values and size for each cluster:
datamart_rfm_k2.groupby(['Cluster']).agg({
    'Recency': 'mean',
    'Frequency': 'mean',
    'MonetaryValue': ['mean', 'count'],
}).round(0)


## Choosing number of clusters - Elbow Method

1. Plot the number of clusters against within-cluster sum-of-squared-errors (SSE):
SSE = sum of squared distances from every data point to their cluster center
2. Identify an "elbow" in the plot
3. Elbow - a point representing an "optimal" number of clusters

- Best to choose the point on elbow, or the next point 
- Use as a guide but test multiple solutions


# Import key libraries
from sklearn.cluster import KMeans
import seaborn as sns
from matplotlib import pyplot as plt
# Fit KMeans and calculate SSE for each *k*
sse = {}
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=1)
    kmeans.fit(data_normalized)
    sse[k] = kmeans.inertia_ # sum of squared distances to closest cluster center
# Plot SSE for each *k*
plt.title('The Elbow Method')
plt.xlabel('k'); plt.ylabel('SSE')
sns.pointplot(x=list(sse.keys()), y=list(sse.values()))
plt.show()


## Choosing number of clusters - Experimental approach - analyze segments

- Build clustering at and around elbow solution
- Analyze their properties - average RFM values
- Compare against each other and choose one which makes most business sense


## Customer personas

- Summary statistics for each cluster e.g. average RFM values
- Snake plots (from market research)
- Relative importance of cluster attributes compared to population

# Run k-means segmentation for several k values around the recommended value.
# Create a cluster label column in the original DataFrame:
datamart_rfm_k2 = datamart_rfm.assign(Cluster = cluster_labels)
# Calculate average RFM values and sizes for each cluster:
datamart_rfm_k2.groupby(['Cluster']).agg({
     'Recency': 'mean',
     'Frequency': 'mean',
     'MonetaryValue': ['mean', 'count'],
 }).round(0)
# Repeat the same for k=3


## Snake plots

- Market research technique to compare different segments
- Visual representation of each segment's attributes
- Need to first normalize data (center & scale)
- Plot each cluster's average normalized values of each attribute


# Transform datamart_normalized as DataFrame and add a Cluster column
datamart_normalized = pd.DataFrame(datamart_normalized, 
                                   index=datamart_rfm.index, 
                                   columns=datamart_rfm.columns)
datamart_normalized['Cluster'] = datamart_rfm_k3['Cluster']
# Melt the data into a long format so RFM values and metric names are stored in 1 column each
datamart_melt = pd.melt(datamart_normalized.reset_index(), 
                    id_vars=['CustomerID', 'Cluster'],
                    value_vars=['Recency', 'Frequency', 'MonetaryValue'], 
                    var_name='Attribute', 
                    value_name='Value')
# Visualize the snake plot
plt.title('Snake plot of standardized variables')
plt.xlabel('Metric')
plt.ylabel('Value')
sns.lineplot(x="Attribute", y="Value", hue='Cluster', data=datamart_melt)


## Relative importance of segment attributes

- Useful technique to identify relative importance of each segment's attribute
- Calculate average values of each cluster
- Calculate average values of population
- Calculate importance score by dividing them and subtracting 1 (ensures 0 is returned when cluster average equals population average)
 
cluster_avg = datamart_rfm_k3.groupby(['Cluster']).mean()
population_avg = datamart_rfm.mean()
relative_imp = cluster_avg / population_avg - 1
print(relative_imp.round(2))

- The further a ratio is from 0, the more important that attribute is for a segment relative to the total population.
 
relative_imp.round(2)
          Recency  Frequency  MonetaryValue
Cluster                                   
0          -0.82       1.68           1.83
1           0.84      -0.84          -0.86
2          -0.15      -0.34          -0.42

# Plot a heatmap for easier interpretation:
plt.figure(figsize=(8, 2))
plt.title('Relative importance of attributes')
sns.heatmap(data=relative_imp, annot=True, fmt='.2f', cmap='RdYlGn')
plt.show()



## Key steps of the segmentation project

- Gather data - updated data with an additional variable (Tenure = how long customer has been with the company)
- Pre-process the data
- Explore the data and decide on the number of clusters
- Run k-means clustering
- Analyze and visualize results


# Import StandardScaler 
from sklearn.preprocessing import StandardScaler
# Apply log transformation
datamart_rfmt_log = np.log(datamart_rfmt)
# Initialize StandardScaler and fit it 
scaler = StandardScaler()
scaler.fit(datamart_rfmt_log)
# Transform and store the scaled data as datamart_rfmt_normalized
datamart_rfmt_normalized = scaler.transform(datamart_rfmt_log)
print(datamart_rfmt)
print(datamart_rfmt_normalized)

# Import KMeans 
from sklearn.cluster import KMeans
# Initialize empty dictionary
sse = {}
# Fit KMeans and calculate SSE for each k between 1 and 10
for k in range(1, 11):
    # Initialize KMeans with k clusters and fit it 
    kmeans = KMeans(n_clusters = k, random_state=1).fit(datamart_rfmt_normalized)
    # Assign sum of squared distances to k element of the sse dictionary
    sse[k] = kmeans.inertia_   

# Add the plot title, x and y axis labels
plt.title('The Elbow Method'); plt.xlabel('k'); plt.ylabel('SSE')
# Plot SSE values for each k stored as keys in the dictionary
sns.pointplot(x=list(sse.keys()), y=list(sse.values()))
plt.show()

# Import KMeans 
from sklearn.cluster import KMeans
# Initialize KMeans
kmeans = KMeans(n_clusters=4, random_state=1) 
# Fit k-means clustering on the normalized data set
kmeans.fit(datamart_rfmt_normalized)
# Extract cluster labels
cluster_labels = kmeans.labels_
print(cluster_labels)

# Create a new DataFrame by adding a cluster label column to datamart_rfmt
datamart_rfmt_k4 = datamart_rfmt.assign(Cluster=cluster_labels)
# Group by cluster
grouped = datamart_rfmt_k4.groupby(['Cluster'])
# Calculate average RFMT values and segment sizes for each cluster
print(grouped.agg({
    'Recency': 'mean',
    'Frequency': 'mean',
    'MonetaryValue': 'mean',
    'Tenure': ['mean', 'count']
  }).round(1)
  )



































